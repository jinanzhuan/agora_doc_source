<?xml version="1.0" encoding="UTF-8"?>
<!DOCTYPE reference PUBLIC "-//OASIS//DTD DITA Reference//EN" "reference.dtd">
<reference id="callback_iaudioframeobserverbase_onearmonitoringaudioframe">
    <title><ph keyref="onEarMonitoringAudioFrame"/></title>
    <shortdesc id="short"><ph id="shortdesc">Gets the in-ear monitoring audio
        frame.</ph></shortdesc>
    <prolog>
        <metadata>
            <keywords>
                <indexterm keyref="onEarMonitoringAudioFrame"/>
            </keywords>
        </metadata>
    </prolog>
    <refbody>
        <section id="prototype">
            <p outputclass="codeblock">
                <codeblock props="android" outputclass="language-java">public abstract boolean onEarMonitoringAudioFrame(int type, int samplesPerChannel,
    int bytesPerSample, int channels, int samplesPerSec, ByteBuffer buffer, long renderTimeMs,
    int avsync_type);
</codeblock>
                <codeblock props="ios mac" outputclass="language-objectivec">- (BOOL)onEarMonitoringAudioFrame:(AgoraAudioFrame* _Nonnull)frame;
</codeblock>
                <codeblock props="cpp" outputclass="language-cpp">virtual bool onEarMonitoringAudioFrame(AudioFrame&amp; audioFrame) = 0;</codeblock></p>
        </section>
        <section id="detailed_desc">
            <note type="note" id="note">
                <ul>
                    <li>Before joining the channel, you need to call the <xref
                            keyref="registerAudioFrameObserver"/> to register audio observer object,
                        that is, register the <apiname keyref="onEarMonitoringAudioFrame"/>
                        callback.</li>
                    <li>In order to ensure that the obtained in-ear audio data meets the
                        expectations, Agora recommends that you choose one of the following two
                        methods to set the in-ear monitoring-ear audio data format:<ul>
                            <li>If you call <xref keyref="setEarMonitoringAudioFrameParameters"/> to
                                set the acquired audio data format, the SDK calculates the sampling
                                interval according to the parameters in this method, and triggers
                                the <apiname keyref="onEarMonitoringAudioFrame"/> callback according
                                to the sampling interval.</li>
                            <li>If you set the acquired audio data format in the return value of the
                                    <xref keyref="getEarMonitoringAudioParams"/> callback, the SDK
                                calculates the sampling interval according to the return value of
                                the callback, and trigger the <apiname
                                    keyref="onEarMonitoringAudioFrame"/> callback according to the
                                sampling interval.</li>
                        </ul></li>
                </ul>
            </note>
        </section>
        <section id="parameters" conkeyref="onMixedAudioFrame/parameters"/>
        <section id="return_values" conkeyref="onMixedAudioFrame/return_values"/>
    </refbody>
</reference>
